{
 "metadata": {
  "name": "",
  "signature": "sha256:0b5ef95fbe3b0501dc20da278dba647397a92847f84e7ffa08ccc18315e3f09d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import dateutil.parser\n",
      "import urllib\n",
      "\n",
      "def to_date(datestring):\n",
      "    date = dateutil.parser.parse(datestring)\n",
      "    return date\n",
      "\n",
      "def money_to_int(moneystring):\n",
      "    try:\n",
      "        moneystring = moneystring.replace('$','').replace(',','')\n",
      "        return int(moneystring)\n",
      "    except:\n",
      "        return None\n",
      "    \n",
      "def clear_url(raw_url):\n",
      "    tmp_url = raw_url.replace('(','').replace(')','').replace('-',' ').replace('.','')\n",
      "    tmp_url = tmp_url.replace(u'\u00e9','e').replace(u'\u00e2','a').replace(',','e').encode('latin1','ignore')\n",
      "    return tmp_url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = []\n",
      "#url = \"http://www.forum-auto.com/marques/renault/sujet5226-1260.htm\"\n",
      "#print range(0,2135,35)\n",
      "url = \"http://www.forum-auto.com/marques/renault/sujet5226-\"\n",
      "\n",
      "#for scan in range(0,2135,35):\n",
      "for scan in range(0,35,35):\n",
      "    scan_page = url+str(scan+1260)+'.htm'\n",
      "    print scan_page\n",
      "    page = urllib2.urlopen(scan_page)\n",
      "    soup = BeautifulSoup(page)\n",
      "    case1 = soup.findAll(\"td\", { \"class\" : \"messCase1\" })\n",
      "    case2 = soup.findAll(\"td\", { \"class\" : \"messCase2\" })\n",
      "    user = case1[0].find(\"span\").text ###\n",
      "    posted = case2[0].find(\"div\", { \"class\" : \"toolbar\" }).find(\"div\", { \"class\" : \"left\" }).text\n",
      "    print user\n",
      "    print posted"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.forum-auto.com/marques/renault/sujet5226-1260.htm\n",
        "renaultboy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a018:03:32\u00a0\u00a0\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print case2[0].find(\"div\", { \"class\" : \"toolbar\" }).text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a018:03:32\u00a0\u00a0\u00a0\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subtree = case2[0].find(\"span\", { \"class\" : \"edited\" })\n",
      "print subtree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subtree = case2[0].find(\"div\", { \"class\" : \"toolbar\" })\n",
      "subtree.extract()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "<div class=\"toolbar\"><div class=\"left\">Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a018:03:32\u00a0\u00a0<span class=\"md_noclass_cryptlinkaHR0cDovL3d3dy5mb3J1bS1hdXRvLmNvbS9tYXJxdWVzL3JlbmF1bHQvY2l0ZXItNTIyNi0xOTM1OTYyLTM3LTAuaHRtI2Zvcm11bGFpcmU=\"><img alt=\"answer\" class=\"replywithquote\" height=\"13\" src=\"http://images.forum-auto.com/themes_static/images_forum/6/quote.gif?v=1421834571\" title=\"R\u00e9pondre \u00e0 ce message\" width=\"17\"/></span><a class=\"addtoquotelist\" href=\"http://www.forum-auto.com/marques/renault/citer-5226-1935962-37-0.htm#formulaire\" onclick=\"quoter('marques','3',5226,1935962); return false;\" rel=\"nofollow\"><img alt=\"answer +\" height=\"13\" id=\"plus1935962\" src=\"http://images.forum-auto.com/themes_static/images_forum/6/quote+.gif?v=1421834571\" style=\"display:none\" title=\"Ajouter \u00e0 la liste des messages cit\u00e9s\" width=\"18\"/><img alt=\"answer -\" height=\"13\" id=\"moins1935962\" src=\"http://images.forum-auto.com/themes_static/images_forum/6/quote-.gif?v=1421834571\" style=\"display:none\" title=\"Retirer de la liste des messages cit\u00e9s\" width=\"18\"/></a><a href=\"http://www.forum-auto.com/configuration.php?config=marques.inc&amp;pseudo=renaultboy\" target=\"_blank\"><img alt=\"config\" height=\"15\" src=\"http://images.forum-auto.com/themes_static/images_forum/6/config.gif?v=1421834571\" title=\"V\u00e9hicules poss\u00e9d\u00e9s : voitures, motos, bateaux\" width=\"15\"/></a></div><div class=\"right\"><span class=\"DOC_cryptlinkaHR0cDovL3d3dy5mb3J1bS1hdXRvLmNvbS91c2VyL21vZG8ucGhwP2NhdD0zJnJlZj0wJnBvc3Q9NTIyNiZwYWdlPTM3JmNvbmZpZz1tYXJxdWVzLmluYyZudW1yZXBvbnNlPTE5MzU5NjImcmVmPTA= DOC_cryptlink alertmoderator\" id=\"topicalertmoderator\" onclick=\"return DOC_popup(this);\" rel=\"nofollow\" title=\"Pr\u00e9venir les mod\u00e9rateurs en cas d'abus\"><img alt=\"Pr\u00e9venir les mod\u00e9rateurs en cas d'abus\" height=\"16\" src=\"http://images.forum-auto.com/themes_static/images_forum/6/exclam.gif?v=1421834571\" width=\"16\"/></span></div><div class=\"spacer\">\u00a0</div></div>"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subtree = case2[0].find(\"table\", { \"class\" : \"citation\" })\n",
      "subtree.extract()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "<table class=\"citation\"><tr class=\"none\"><td><b class=\"s1\"><a class=\"Topic\" href=\"http://www.forum-auto.com/marques/renault/sujet5226-1225.htm#t1933070\">dididu95 a \u00e9crit :</a></b><br/><br/><p><br/>Toi tu t'es inscris \u00e0 l'amphi. <img alt=\";)\" class=\"wysiwyg_smiley\" src=\"http://staticclub.caradisiac.com/design/smilies/wink.gif\" title=\";)\"/> <br/><br/></p></td></tr></table>"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subtree = case2[0].find(\"div\", { \"class\" : \"edited\" })\n",
      "subtree.extract()\n",
      "subtree = case2[0].find(\"div\", { \"class\" : \"edited\" })\n",
      "subtree.extract()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "<div class=\"edited\"><a class=\"cLink\" href=\"http://www.forum-auto.com/forum2.php?config=marques.inc&amp;cat=3&amp;post=5226&amp;page=1&amp;p=1&amp;sondage=0&amp;owntopic=0&amp;trash=&amp;trash_post=&amp;print=&amp;numreponse=1935962&amp;quote_only=1&amp;new=&amp;nojs=0\" rel=\"nofollow\">Message cit\u00e9 3 fois</a><br/>Message \u00e9dit\u00e9 par renaultboy le 16-09-2014\u00a0\u00e0\u00a018:18:47</div>"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subtree = case2[0].find(\"span\", { \"class\" : \"signature\" })\n",
      "subtree.extract()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'NoneType' object has no attribute 'extract'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-93-08499290a7d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"class\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"signature\"\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'extract'"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print case2[0].find(\"div\", {\"id\": \"para1935962\"}).getText(\" \")\n",
      "print case2[0].getText(\" \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " Reprise du message pr\u00e9c\u00e9dent : J'ai particip\u00e9 \u00e0 celui de ce jour. Il est tr\u00e8s beau, tr\u00e8s pur et enfin des technologies nouvelles sur une Renault. Tr\u00e8s impressionn\u00e9 par le niveau technologique g\u00e9n\u00e9ral. J'esp\u00e8re que la client\u00e8le vis\u00e9e sera sensible \u00e0 tout cela. NEW GAMME DACIA, CLIO IV, CAPTUR, TWINGO 3, FUTUR ESPACE (on ne connait pas encore son nom..) : RENAULT RESSORT VRAIEMENT TRES TRES FORT DE LA CRISE LE GROUPE RENAULT EST ENTRAIN DE DEVENIR UN HIT AUTOMOBILE, nous pouvons \u00eatre tr\u00e8s fier de ce que r\u00e9alise l'entreprise depuis 3 ans \n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print case2[2].getText(\" \")\n",
      "print case1[2].find(\"span\").text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a018:49:01\u00a0\u00a0 \u00a0 davdu71 a \u00e9crit : Moi je me suis laiss\u00e9 entendre dire que Daimler avait aid\u00e9 \u00e0 la conception de ce futur Espace   ) Je ne sais pas... Message \u00e9dit\u00e9 par renaultboy le 16-09-2014\u00a0\u00e0\u00a020:04:39  ---------------\r\n",
        "\t\t\t RENAULT IS BACK RENAULT, MORE BUSINESS RENAULT, SO........SEX\n",
        "renaultboy\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print case2[3].getText(\" \")\n",
      "print case1[3].find(\"span\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a018:49:01\u00a0\u00a0 \u00a0 \n",
        " \n",
        " \r\n",
        "<!--\r\n",
        "CaraShow_ad('AncrageForum');\r\n",
        "-->\r\n",
        " \n",
        " \n",
        " \n",
        "\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print case2[4].getText(\" \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a020:06:32\u00a0\u00a0 \u00a0 Et bravo \u00e0 DOUAI, Conception et fabrication FRANCAISE pour du luxe \u00e0 la FRANCAISE   ---------------\r\n",
        "\t\t\t RENAULT IS BACK RENAULT, MORE BUSINESS RENAULT, SO........SEX\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print case2[5].getText(\" \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Post\u00e9 le 16-09-2014\u00a0\u00e0\u00a020:10:53\u00a0\u00a0 \u00a0 renaultboy a \u00e9crit : J'ai particip\u00e9 \u00e0 celui de ce jour. Il est tr\u00e8s beau, tr\u00e8s pur et enfin des technologies nouvelles sur une Renault. Tr\u00e8s impressionn\u00e9 par le niveau technologique g\u00e9n\u00e9ral. J'esp\u00e8re que la client\u00e8le vis\u00e9e sera sensible \u00e0 tout cela. NEW GAMME DACIA, CLIO IV, CAPTUR, TWINGO 3, FUTUR ESPACE (on ne connait pas encore son nom..) : RENAULT RESSORT VRAIEMENT TRES TRES FORT DE LA CRISE LE GROUPE RENAULT EST ENTRAIN DE DEVENIR UN HIT AUTOMOBILE, nous pouvons \u00eatre tr\u00e8s fier de ce que r\u00e9alise l'entreprise depuis 3 ans    \u00a0   Dommage d'avoir rat\u00e9 \u00e7a. Message cit\u00e9 1 fois  ---------------\r\n",
        "\t\t\t - Peugeot 206 1.9D 291500 km - laguna coup\u00e9 GT 205 noir 32200 km \u00a0 http://www.forum-auto.com/marq [...] 1-2310.htm\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print case2[37].getText(\" \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Post\u00e9 le 17-09-2014\u00a0\u00e0\u00a019:44:15\u00a0\u00a0 \u00a0 davdu71 a \u00e9crit : Pas toujours, l'un des principaux crit\u00e8re d'achat en Chine c'est l'habitabilit\u00e9 et notamment, la longueur aux places arri\u00e8res. Mais la France est tr\u00e8s bien vu en Chine, il n'y a qu'a voir les marques haut-de-gamme comme Dior, LVMH... qui r\u00e9alisent de tr\u00e8s bon chiffres de vente. Un jour Initial Paris pour Renault...  ---------------\r\n",
        "\t\t\t RENAULT IS BACK RENAULT, MORE BUSINESS RENAULT, SO........SEX\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for scan in ['2014','2013','2012','2011','2010']:\n",
      "    for scan_page in [str(x+1) for x in range(4)]:\n",
      "        page = urllib2.urlopen(url+scan+'&pagenum='+scan_page)\n",
      "        soup = BeautifulSoup(page)\n",
      "        try:\n",
      "            table = soup.find_all('table')\n",
      "            data_table = table[4]\n",
      "            rows = data_table.find_all('tr')\n",
      "            for row in rows[1:]:\n",
      "                cols = row.find_all('td')\n",
      "                cols = [ele.text.strip() for ele in cols]\n",
      "                cols[4]=cols[4]+'/'+scan\n",
      "                data.append(cols)\n",
      "        except IndexError:\n",
      "            pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get more info from Mojo for each movie we will have to visit its specific Mojo page which we will find with the Mojo search engine. From the search result, we will pick the movie that has a US release date within 180 days from the French release date. The search engine gives information such as the Studio, US box office, US number of theaters as well as the revenue and number of theaters of the US opening week-end ; and once on the movie page, we can get information such as the Director of the movie."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_with_url_and_release_dates = [['FrenchRank',\n",
      "                                    'MovieName',\n",
      "                                    'MojoUrl',\n",
      "                                    'FrenchDistributor',\n",
      "                                    'FrenchGross',\n",
      "                                    'FrenchReleaseDate',\n",
      "                                    'Studio',\n",
      "                                    'USGross',\n",
      "                                    'USNumberOfTheaters',\n",
      "                                    'USOpening',\n",
      "                                    'USOpeningTheaters',\n",
      "                                    'USReleaseDate',\n",
      "                                    'Director']]\n",
      "for row in data:\n",
      "    url = \"http://boxofficemojo.com/search/?q=\"\n",
      "    query = urllib.quote(clear_url(row[1]))\n",
      "    try:\n",
      "        page = urllib2.urlopen(url+query)\n",
      "        soup = BeautifulSoup(page)\n",
      "        content = []\n",
      "        release_date_given = to_date(row[4])\n",
      "        \n",
      "        try:\n",
      "            table = soup.find_all('table')\n",
      "            link_table = table[4]\n",
      "            rows = link_table.find_all('tr')\n",
      "            for x in rows[1:]:\n",
      "                cols = x.find_all('td')\n",
      "                col_with_link = cols[0]\n",
      "                col_with_release_date = cols[6]\n",
      "                try:\n",
      "                    release_date_searched = to_date(col_with_release_date.text)                    \n",
      "                except ValueError:\n",
      "                    pass\n",
      "                delta = release_date_searched - release_date_given\n",
      "                if abs(delta.days) < 180:\n",
      "                    matching_url = 'http://boxofficemojo.com'+col_with_link.find('a')['href']\n",
      "                    director = url_to_director(matching_url)\n",
      "                    row_data = [int(row[0]), # french rank\n",
      "                                row[1], # name of the movie\n",
      "                                matching_url, # url\n",
      "                                row[2], # distributor\n",
      "                                money_to_int(row[3]), # french gross\n",
      "                                release_date_given, # french release date\n",
      "                                cols[1].text, # studio\n",
      "                                money_to_int(cols[2].text), # us gross\n",
      "                                money_to_int(cols[3].text), # us number of theaters\n",
      "                                money_to_int(cols[4].text), # us opening\n",
      "                                money_to_int(cols[5].text), # number of us opening theaters\n",
      "                                release_date_searched, # us release date\n",
      "                                director] # us director\n",
      "                    data_with_url_and_release_dates.append(row_data)\n",
      "                    break\n",
      "        except:\n",
      "            pass\n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save data to a cvs file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import csv\n",
      "\n",
      "with open('nasdag_luther_data.csv', 'w') as csvfile:\n",
      "    writer = csv.writer(csvfile)\n",
      "    for row in data_with_url_and_release_dates:\n",
      "        row = [c.encode('utf8') if isinstance(c, unicode) else c for c in row]\n",
      "        writer.writerow(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before scraping data from Allocin\u00e9 we need to define some functions.\n",
      "\n",
      "The first one will use the search engine of Allocin\u00e9 to find the corresponding movie page of a movie name with a release date and a director."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def allocine(movie_name, release_date_given, director):\n",
      "    url = \"http://www.allocine.fr/recherche/?q=\"\n",
      "    query = clear_url(movie_name.replace(' ','+'))\n",
      "    page = urllib2.urlopen(url+query)\n",
      "    soup = BeautifulSoup(page)\n",
      "\n",
      "    try:\n",
      "        table = soup.find_all('table')\n",
      "        link_table = table[0]\n",
      "        rows = link_table.find_all('tr')\n",
      "        for x in rows:\n",
      "            try:\n",
      "                cols = x.find_all('td')\n",
      "                col_with_link = cols[1]\n",
      "                search_text = col_with_link.find(class_='fs11').text\n",
      "                release_date_year = search_text.split()[0]\n",
      "                if release_date_year == release_date_given and director in search_text:\n",
      "                    fr_movie_url = 'http://www.allocine.fr'+col_with_link.find('a')['href']\n",
      "                    return fr_movie_url\n",
      "            except:\n",
      "                pass\n",
      "    except:\n",
      "        pass\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function will locate the rating and the number of entries in a given Allocin\u00e9 movie page"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def french_press_rating_with_entries(fr_movie_link):\n",
      "    page = urllib2.urlopen(fr_movie_link)\n",
      "    soup = BeautifulSoup(page)\n",
      "    try:\n",
      "        note = soup.find(class_='note').text.replace(',','.')\n",
      "        entries = \"\".join(soup.find_all(class_=\"visible\")[1].find_all('td')[2].text.split()[:-1])\n",
      "        return float(note), int (entries)\n",
      "    except:\n",
      "        pass\n",
      "    return None, None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function will locate the Director name in a given Mojo movie page (used during data scraping from Mojo)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def url_to_director(url):\n",
      "    page = urllib2.urlopen(url)\n",
      "    soup = BeautifulSoup(page)\n",
      "    \n",
      "    cells = soup.find_all('td')\n",
      "    \n",
      "    previous = cells[0]\n",
      "    for cell in cells[1:]:\n",
      "        if previous.find(text='Director:') or previous.find(text='Directors:') or previous.find(text='Producers:'):\n",
      "            return cell.find_all('a')[0].text\n",
      "        previous = cell\n",
      "    return ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now load the date of the previous data scraping phase"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "cr = csv.reader(open('nasdag_luther_data.csv','rb'))\n",
      "data_with_url_and_release_dates = []\n",
      "for row in cr:\n",
      "    data_with_url_and_release_dates.append(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can run the data scraping script on Allocin\u00e9 and append the French rating and number of entries to each movie"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dateutil import parser\n",
      "\n",
      "data_with_allocine = []\n",
      "\n",
      "row0 = data_with_url_and_release_dates[0]\n",
      "row0.append('FrRating')\n",
      "row0.append('FrEntries')\n",
      "\n",
      "data_with_allocine.append(row0)\n",
      "\n",
      "for row in data_with_url_and_release_dates[1:]:\n",
      "    try:\n",
      "        french_url = allocine(row[1], str(parser.parse(row[5]).year), row[12])\n",
      "        fr_rating, fr_entries = french_press_rating_with_entries(french_url)\n",
      "        row_data = row\n",
      "        row_data.append(fr_rating)\n",
      "        row_data.append(fr_entries)\n",
      "        data_with_allocine.append(row_data)\n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And finally save the complete data to a cvs file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('nasdag_luther_data_with_french_rating.csv', 'w') as csvfile:\n",
      "    writer = csv.writer(csvfile)\n",
      "    for row in data_with_url_and_release_dates:\n",
      "        row = [c.encode('utf8') if isinstance(c, unicode) else c for c in row]\n",
      "        writer.writerow(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}